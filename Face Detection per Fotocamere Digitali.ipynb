{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374c59f5-850d-4862-9e32-3526262fa10a",
   "metadata": {},
   "source": [
    "#  Progetto di Identificazione dei Volti con Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d312a78-875e-4132-a4df-08f24a2f13f9",
   "metadata": {},
   "source": [
    "## Obiettivo del Progetto\n",
    " \n",
    "L'obiettivo di questo progetto è sviluppare un affidabile sistema di identificazione dei volti che, attraverso l'utilizzo di tecniche di machine learning e computer vision, sia in grado di rilevare i volti presenti in una immagine e fornire le coordinate dei bounding box che li circondano. Questo sistema dovrà operare efficientemente anche su hardware con limitate capacità di calcolo, assicurando così una vasta compatibilità e accessibilità.\n",
    "\n",
    "**Task del Progetto**\n",
    "\n",
    "1. **Ricerca e Selezione del Dataset**:\n",
    "   - Individuare e selezionare un dataset pubblico di riconoscimento facciale adatto allo scopo.\n",
    "   - Preparare i dati per l'addestramento, inclusa l'eventuale pulizia, normalizzazione e annotazione dei bounding box.\n",
    "\n",
    "2. **Esplorazione e Preparazione dei Dati**:\n",
    "   - Analizzare il dataset per comprenderne le caratteristiche e le potenziali sfide.\n",
    "   - Implementare le procedure di pre-processing necessarie per preparare i dati all'addestramento.\n",
    "\n",
    "3. **Scelta del Modello e Addestramento**:\n",
    "   - Condurre una ricerca bibliografica per identificare i modelli di machine learning più adatti e meno onerosi in termini computazionali.\n",
    "   - Sviluppare e addestrare il modello sul dataset selezionato, effettuando anche la validazione crociata per testarne l'efficacia.\n",
    "\n",
    "4. **Implementazione della Pipeline di Predizione**:\n",
    "   - Creare una pipeline scikit-learn che integri le fasi di pre-elaborazione dei dati, estrazione delle feature, e inferenza del modello.\n",
    "   - Ottimizzare la pipeline per massimizzare le performance mantenendo bassi i requisiti computazionali.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d95a774-bbd0-4bfb-af58-e7ca5d588b12",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86be576-8eb2-4fca-956c-aa18f174a75a",
   "metadata": {},
   "source": [
    "# 1. Il Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3e33d-4d69-448a-b40f-9e8aef4539cc",
   "metadata": {},
   "source": [
    "Cominceremo a lavorare con un esempio di dataset che include sia immagini di volti sia immagini senza volti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be4a29-0817-4ecf-9378-65db13323b8e",
   "metadata": {},
   "source": [
    "Il database che include i volti e le relative coordinate è stato scaricato da Kaggle, sotto il nome \"Human Faces (Object Detection)\", e si trova al seguente indirizzo: https://www.kaggle.com/datasets/sbaghbidi/human-faces-object-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7567233-6379-4d6d-82c8-6db6062cfc9b",
   "metadata": {},
   "source": [
    "Nel contesto del nostro progetto, abbiamo strutturato il dataset in una directory principale divisa in due sottodirectory: \"Faces\", contenente immagini con volti umani, e \"No_faces\", che verrà compilata con immagini casuali prive di volti. Questa organizzazione facilita l'addestramento del modello di machine learning non solo nel riconoscere volti umani ma anche nel distinguere le situazioni in cui questi non sono presenti.\n",
    "\n",
    "All'interno della cartella \"Faces\", abbiamo incluso un file cruciale per il processo di addestramento, denominato \"faces.csv\". Questo file elenca tutte le immagini che contengono volti, specificando con precisione le coordinate dei volti all'interno di ciascuna immagine. Per le immagini raccolte nella sottodirectory \"No_faces\", invece, verranno annotati soltanto i nomi dei file. Quest'approccio mira a ottimizzare l'efficacia del modello nel distinguere tra immagini con e senza volti, elemento fondamentale per il successo del nostro progetto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9853ade0-300e-43d9-a2a7-0f9de88a34c5",
   "metadata": {},
   "source": [
    "Iniziamo quindi ad osservare il file **faces.csv** fornito dal dataset \"Human Faces (Object Detection)\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868e3405-a185-4078-91ec-5f13514e1e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001722.jpg</td>\n",
       "      <td>1333</td>\n",
       "      <td>2000</td>\n",
       "      <td>490</td>\n",
       "      <td>320</td>\n",
       "      <td>687</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001044.jpg</td>\n",
       "      <td>2000</td>\n",
       "      <td>1333</td>\n",
       "      <td>791</td>\n",
       "      <td>119</td>\n",
       "      <td>1200</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001050.jpg</td>\n",
       "      <td>667</td>\n",
       "      <td>1000</td>\n",
       "      <td>304</td>\n",
       "      <td>155</td>\n",
       "      <td>407</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001736.jpg</td>\n",
       "      <td>626</td>\n",
       "      <td>417</td>\n",
       "      <td>147</td>\n",
       "      <td>14</td>\n",
       "      <td>519</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00003121.jpg</td>\n",
       "      <td>626</td>\n",
       "      <td>418</td>\n",
       "      <td>462</td>\n",
       "      <td>60</td>\n",
       "      <td>599</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>00002232.jpg</td>\n",
       "      <td>620</td>\n",
       "      <td>349</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>186</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>00002232.jpg</td>\n",
       "      <td>620</td>\n",
       "      <td>349</td>\n",
       "      <td>122</td>\n",
       "      <td>103</td>\n",
       "      <td>344</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>00002232.jpg</td>\n",
       "      <td>620</td>\n",
       "      <td>349</td>\n",
       "      <td>258</td>\n",
       "      <td>118</td>\n",
       "      <td>541</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>00002232.jpg</td>\n",
       "      <td>620</td>\n",
       "      <td>349</td>\n",
       "      <td>215</td>\n",
       "      <td>11</td>\n",
       "      <td>362</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>00002232.jpg</td>\n",
       "      <td>620</td>\n",
       "      <td>349</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3350 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  width  height   x0   y0    x1   y1\n",
       "0     00001722.jpg   1333    2000  490  320   687  664\n",
       "1     00001044.jpg   2000    1333  791  119  1200  436\n",
       "2     00001050.jpg    667    1000  304  155   407  331\n",
       "3     00001736.jpg    626     417  147   14   519  303\n",
       "4     00003121.jpg    626     418  462   60   599  166\n",
       "...            ...    ...     ...  ...  ...   ...  ...\n",
       "3345  00002232.jpg    620     349    4   36   186  158\n",
       "3346  00002232.jpg    620     349  122  103   344  248\n",
       "3347  00002232.jpg    620     349  258  118   541  303\n",
       "3348  00002232.jpg    620     349  215   11   362  108\n",
       "3349  00002232.jpg    620     349  330    1   487   81\n",
       "\n",
       "[3350 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv(\"./dataset/faces.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49e8ed-e4bc-457e-a839-242ec93e1a16",
   "metadata": {},
   "source": [
    "Per il training sui casi negativi è necessario includere nel dataset un file CSV chiamato \"no_faces.csv\" per annotare le immagini negative. Di conseguenza, creeremo un file aggiuntivo che conterrà i nomi di tutti i file delle immagini senza volti.<br> Questo passaggio ci permetterà di addestrare il modello non solo a identificare presenze umane ma anche a riconoscere i casi negativi, migliorando la sua capacità di distinguere tra immagini con e senza volti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23e7f379-918c-471c-b102-656a017ee4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = './dataset/no_face/'\n",
    "image_name = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    image_name.append('no_face/'+file)\n",
    "    \n",
    "df_out = pd.DataFrame(columns=['image_name'],data=image_name)\n",
    "df_out.to_csv(\"./dataset/no_faces.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3444fe-9823-4c7d-9537-9bad1b94d605",
   "metadata": {},
   "source": [
    "Adesso abbiamo sia i casi positivi che i casi negativi utili per addestrare il nostro modello."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ab13c-a6eb-4e91-975f-d9d85548cc56",
   "metadata": {},
   "source": [
    "# 2. Addestramento di un classificatore a cascata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07942974-8ca9-4657-a0e0-e971dcd5996d",
   "metadata": {},
   "source": [
    "Utilizzando la documentazione online di OpenCV (https://docs.opencv.org/2.4.13.2/doc/user_guide/ug_traincascade.html) adotteremo quindi **l'addestramento di un Classificatore a Cascata.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6c3dc-fbc5-468a-b844-36a210f07a04",
   "metadata": {},
   "source": [
    "Seguendo la documentazione, il passo successivo, dopo aver preparato il nostro dataset, è addestrare un classificatore a cascata in OpenCV per il rilevamento dei volti. <br>\n",
    "<br>Utilizzeremo **opencv_createsamples**, uno strumento specificamente progettato per generare un campione di vettori positivi. Questo processo implica combinare le immagini positive (quelle che contengono i volti che intendiamo rilevare) con le relative annotazioni. Tali annotazioni, che forniscono dettagli sui bounding box attorno ai volti presenti nelle immagini, sono tipicamente salvate in un file CSV dedicato. Per il nostro progetto, utilizzeremo il file CSV già disponibile nel dataset scaricato da Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b1ba5-0531-45be-831a-09473d268849",
   "metadata": {},
   "source": [
    "Tramite la funzione **opencv_createsamples**, combineremo dunque le immagini positive, ovvero quelle che includono gli oggetti di nostro interesse come i volti, con le loro annotazioni, in un unico file di vettori .vec. Questo file .vec fungerà da contenitore per tutte le informazioni relative alle immagini positive e alle loro annotazioni. È il formato richiesto dal processo di addestramento del classificatore per identificare gli oggetti di interesse nelle immagini. Questo approccio consente di semplificare e ottimizzare il processo di addestramento, fornendo al classificatore tutte le informazioni necessarie in un formato facilmente accessibile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8169c30-b44d-4466-b1ce-c2f0578f6ca7",
   "metadata": {},
   "source": [
    "Nota sul file annotazioni :\n",
    "\n",
    "E' necessario fornire manualmente un file di annotazioni che contenga le informazioni sulle posizioni dei bounding boxes degli oggetti di interesse nelle immagini positive.\n",
    "\n",
    "Il file di annotazioni è un documento testuale che cataloga i dettagli di ogni immagine con rilevazione positiva nel formato specificato. Solitamente, ciascuna linea del file rappresenta un'immagine positiva e include le informazioni seguenti:\n",
    "\n",
    "    1. Il percorso dell'immagine.\n",
    "    2. Numero di occorrenze degli item individuati\n",
    "    3. Le coordinate e le dimensioni del bounding box che circonda l'oggetto di interesse nell'immagine di riferimento.\n",
    "\n",
    "\n",
    "Ecco un esempio di come potrebbe essere strutturato:\n",
    "\n",
    "\n",
    "/path/to/image1.jpg w1 x1 y1 width1 height1\n",
    "/path/to/image2.jpg w2 x2 y2 width2 height2\n",
    "/path/to/image3.jpg w3 x3 y3 width3 height3\n",
    "\n",
    "Dove:\n",
    "\n",
    "  1. \"/path/to/imageX.jpg\" è il percorso dell'immagine con rilevazione/i positiva/e.\n",
    "  2. \"w\" è il numero di oggetti rilevati nell'immagine\n",
    "  3. \"x1 y1 width1 height1, x2 y2 width2 height2, etc.\" costituiscono le coordinate del bounding box e le dimensioni dell'oggetto di interesse nell'immagine corrispondente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665b5a9-6719-488d-b9bb-7aa40ba635cb",
   "metadata": {},
   "source": [
    "# 3. Pre-processing per Opencv_createsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521aba66-a09d-47b4-aad2-48e70ead5d58",
   "metadata": {},
   "source": [
    "Per adattare il file \"faces.csv\" alla struttura richiesta, ogni immagine sarà documentata rispettando il formato specificato, che include:\n",
    "\n",
    "1. Il nome dell'immagine (un record unico per ogni immagine).\n",
    "2. Il numero di occorrenze (volti) presenti nell'immagine.\n",
    "3. Le coordinate x, y del punto in alto a sinistra di ciascun bounding box.\n",
    "4. La larghezza e l'altezza del bounding box.\n",
    "\n",
    "Questo richiederà di modificare il file \"faces.csv\" affinché rifletta accuratamente queste informazioni per ogni immagine positiva, consentendo così un'efficace elaborazione e addestramento del classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15603d39-25ec-4489-8d50-b40d536b3f15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faces/00001722.jpg</td>\n",
       "      <td>490</td>\n",
       "      <td>320</td>\n",
       "      <td>687</td>\n",
       "      <td>664</td>\n",
       "      <td>197</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faces/00001044.jpg</td>\n",
       "      <td>791</td>\n",
       "      <td>119</td>\n",
       "      <td>1200</td>\n",
       "      <td>436</td>\n",
       "      <td>409</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faces/00001050.jpg</td>\n",
       "      <td>304</td>\n",
       "      <td>155</td>\n",
       "      <td>407</td>\n",
       "      <td>331</td>\n",
       "      <td>103</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>faces/00001736.jpg</td>\n",
       "      <td>147</td>\n",
       "      <td>14</td>\n",
       "      <td>519</td>\n",
       "      <td>303</td>\n",
       "      <td>372</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faces/00003121.jpg</td>\n",
       "      <td>462</td>\n",
       "      <td>60</td>\n",
       "      <td>599</td>\n",
       "      <td>166</td>\n",
       "      <td>137</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>faces/00002232.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>186</td>\n",
       "      <td>158</td>\n",
       "      <td>182</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>faces/00002232.jpg</td>\n",
       "      <td>122</td>\n",
       "      <td>103</td>\n",
       "      <td>344</td>\n",
       "      <td>248</td>\n",
       "      <td>222</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>faces/00002232.jpg</td>\n",
       "      <td>258</td>\n",
       "      <td>118</td>\n",
       "      <td>541</td>\n",
       "      <td>303</td>\n",
       "      <td>283</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>faces/00002232.jpg</td>\n",
       "      <td>215</td>\n",
       "      <td>11</td>\n",
       "      <td>362</td>\n",
       "      <td>108</td>\n",
       "      <td>147</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>faces/00002232.jpg</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>81</td>\n",
       "      <td>157</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3350 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_name   x0   y0    x1   y1  width  height\n",
       "0     faces/00001722.jpg  490  320   687  664    197     344\n",
       "1     faces/00001044.jpg  791  119  1200  436    409     317\n",
       "2     faces/00001050.jpg  304  155   407  331    103     176\n",
       "3     faces/00001736.jpg  147   14   519  303    372     289\n",
       "4     faces/00003121.jpg  462   60   599  166    137     106\n",
       "...                  ...  ...  ...   ...  ...    ...     ...\n",
       "3345  faces/00002232.jpg    4   36   186  158    182     122\n",
       "3346  faces/00002232.jpg  122  103   344  248    222     145\n",
       "3347  faces/00002232.jpg  258  118   541  303    283     185\n",
       "3348  faces/00002232.jpg  215   11   362  108    147      97\n",
       "3349  faces/00002232.jpg  330    1   487   81    157      80\n",
       "\n",
       "[3350 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparazione iniziale del DataFrame con solo le colonne necessarie\n",
    "df_train_annotations = df_train[['image_name', 'x0', 'y0', 'x1', 'y1']].copy()\n",
    "df_train_annotations['image_name'] = 'faces/' + df_train_annotations['image_name']\n",
    "\n",
    "# Calcola width e height come la differenza tra x1 e x0, e y1 e y0, rispettivamente\n",
    "df_train_annotations['width'] = df_train_annotations['x1'] - df_train_annotations['x0']\n",
    "df_train_annotations['height'] = df_train_annotations['y1'] - df_train_annotations['y0']\n",
    "\n",
    "# Mi assicuro di rimuovere le righe con width o height negative\n",
    "df_train_annotations = df_train_annotations[(df_train_annotations['width'] > 0) & (df_train_annotations['height'] > 0)]\n",
    "df_train_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5caf77e-7356-4c8e-bf0a-0d67c733cdea",
   "metadata": {},
   "source": [
    "Adesso avendo calcolato la width e la length per ogni istanza di rettangolo identificata, procederemo ora a organizzare il file in modo che rispetti lo standard previsto da opencv_createsamples. <br>\n",
    "Questo formato richiede che ciascun record corrisponda a un'unica immagine, seguito dal numero di rettangoli rilevati (bounding box) in essa, e quindi dalle quattro informazioni specifiche per ciascun rettangolo: :\n",
    "\n",
    "1. x0\n",
    "2. y0\n",
    "3. Width\n",
    "4. Length\n",
    "\n",
    "Questa strutturazione consentirà di avere un file chiaro e conforme alle necessità di opencv_createsamples, facilitando l'addestramento del modello sui dati forniti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c81e3113-cc43-49ec-9145-0a08143e391a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def definisci_struttura(group):\n",
    "    # Estrae il numero di oggetti e le loro coordinate (aggiornato per usare x0, y0, width, height)\n",
    "    num_objects = group.shape[0]\n",
    "    objects_str = ' '.join([' '.join(map(str, map(int, row))) for row in group[['x0', 'y0', 'width', 'height']].values])\n",
    "   \n",
    "    # Prende il primo nome dell'immagine nel gruppo come rappresentante per tutti\n",
    "    image_name = group['image_name'].iloc[0]\n",
    "    return f\"{image_name} {num_objects} {objects_str}\"\n",
    "\n",
    "# Raggruppa per 'image_name' e applica la funzione di costruzione delle annotazioni secondo il formato predefinito da \"Opencv_createsamples\"\n",
    "annotations = df_train_annotations.groupby('image_name').apply(definisci_struttura).tolist()\n",
    "\n",
    "# Salviamo il file di annotazioni in un file\n",
    ":\n",
    "with open('annotations.txt', 'w') as file:\n",
    "    for annotation in annotations:\n",
    "        file.write(annotation + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a72e4f-aa30-4b31-8e61-1fcbe1691df1",
   "metadata": {},
   "source": [
    "Abbiamo tutto il necessario andiamo ora a lanciare il comando che crea il file .vec utile per l'addestramento (nb. l'esecuzione del comando prevede l'installazione di OpenCV sul sistema operativo) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d001c488-89f2-4a12-889f-8019d3a367d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file name: annotations.txt\n",
      "Img file name: (NULL)\n",
      "Vec file name: positives.vec\n",
      "BG  file name: no_faces.csv\n",
      "Num: 1000\n",
      "BG color: 0\n",
      "BG threshold: 80\n",
      "Invert: FALSE\n",
      "Max intensity deviation: 40\n",
      "Max x angle: 1.1\n",
      "Max y angle: 1.1\n",
      "Max z angle: 0.5\n",
      "Show samples: FALSE\n",
      "Width: 24\n",
      "Height: 24\n",
      "Max Scale: -1\n",
      "RNG Seed: 12345\n",
      "Create training samples from images collection...\n",
      "Done. Created 1000 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='opencv_createsamples -info annotations.txt -num 1000 -w 24 -h 24 -vec positives.vec -bg no_faces.csv', returncode=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "#os.chdir(\"./dataset/\")\n",
    "\n",
    "# Definisci il comando da eseguire\n",
    "command = 'opencv_createsamples -info annotations.txt -num 1000 -w 24 -h 24 -vec positives.vec -bg no_faces.csv'\n",
    "\n",
    "# Esegui il comando\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a12fdb-dee2-4b1b-8eaa-1f6301eed81f",
   "metadata": {},
   "source": [
    "# 4. Training del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5344f06-2e00-4267-a593-6587815cd5cb",
   "metadata": {},
   "source": [
    "Con il file .vec ora pronto, il passo successivo è procedere con l'addestramento del classificatore utilizzando opencv_traincascade. Questo strumento richiede l'utilizzo sia dei dati positivi contenuti nel file .vec che abbiamo appena preparato, sia dei dati negativi, per garantire un addestramento efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca74433-b23b-495a-9286-b911e3269556",
   "metadata": {},
   "source": [
    "Per lanciare **opencv_traincascade** eseguiremo il comando sotto riportato:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2af02b-5dcf-4f86-966d-ef744eead28c",
   "metadata": {},
   "source": [
    "opencv_traincascade -data params -vec positives.vec -bg no_faces.csv -numPos 100 -numNeg 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f9a7b-0e24-4cc5-9066-375e45bf3370",
   "metadata": {},
   "source": [
    "Dove:\n",
    "\n",
    "    -data params: indica la directory \"params\" in questo caso, in cui verranno salvati i dati del classificatore addestrato.\n",
    "    -vec positives.vec: è il file .vec che hai generato con opencv_createsamples.\n",
    "    -bg bg.txt: è il file che elenca le tue immagini negative.\n",
    "    -numPos 100: indica il numero di esempi positivi da utilizzare. Tipicamente, questo dovrebbe essere circa l'80-90% del numero totale di esempi positivi del file .vec.\n",
    "    -numNeg 70: indica il numero di esempi negativi da utilizzare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a44ba7e9-0c27-4588-8b7f-abea9295e602",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETERS:\n",
      "cascadeDirName: params\n",
      "vecFileName: positives.vec\n",
      "bgFileName: no_faces.csv\n",
      "numPos: 100\n",
      "numNeg: 70\n",
      "numStages: 20\n",
      "precalcValBufSize[Mb] : 1024\n",
      "precalcIdxBufSize[Mb] : 1024\n",
      "acceptanceRatioBreakValue : -1\n",
      "stageType: BOOST\n",
      "featureType: HAAR\n",
      "sampleWidth: 24\n",
      "sampleHeight: 24\n",
      "boostType: GAB\n",
      "minHitRate: 0.995\n",
      "maxFalseAlarmRate: 0.5\n",
      "weightTrimRate: 0.95\n",
      "maxDepth: 1\n",
      "maxWeakCount: 100\n",
      "mode: BASIC\n",
      "Number of unique features given windowSize [24,24] : 162336\n",
      "\n",
      "===== TRAINING 0-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 1\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1| 0.114286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 0 seconds.\n",
      "\n",
      "===== TRAINING 1-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.24055\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.214286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 1 seconds.\n",
      "\n",
      "===== TRAINING 2-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.466667\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.614286|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.542857|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.257143|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 3 seconds.\n",
      "\n",
      "===== TRAINING 3-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0973574\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.528571|\n",
      "+----+---------+---------+\n",
      "|   4|        1|      0.6|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.657143|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.314286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 5 seconds.\n",
      "\n",
      "===== TRAINING 4-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.107858\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|      0.5|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 6 seconds.\n",
      "\n",
      "===== TRAINING 5-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0811124\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.642857|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.671429|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.428571|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 8 seconds.\n",
      "\n",
      "===== TRAINING 6-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0434783\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   2|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.657143|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.314286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 10 seconds.\n",
      "\n",
      "===== TRAINING 7-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0601892\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|      0.7|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.414286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 11 seconds.\n",
      "\n",
      "===== TRAINING 8-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0230567\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.757143|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.414286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 13 seconds.\n",
      "\n",
      "===== TRAINING 9-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0207346\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1| 0.742857|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.771429|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.571429|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   6|        1|      0.8|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.557143|\n",
      "+----+---------+---------+\n",
      "|   8|        1| 0.185714|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 16 seconds.\n",
      "\n",
      "===== TRAINING 10-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.0102639\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.771429|\n",
      "+----+---------+---------+\n",
      "|   4|        1|      0.8|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.328571|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 18 seconds.\n",
      "\n",
      "===== TRAINING 11-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00536851\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.671429|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.742857|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.914286|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.357143|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 21 seconds.\n",
      "\n",
      "===== TRAINING 12-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00413589\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   4|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.814286|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.242857|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 24 seconds.\n",
      "\n",
      "===== TRAINING 13-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00301309\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.771429|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.871429|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.685714|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.457143|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 26 seconds.\n",
      "\n",
      "===== TRAINING 14-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00213904\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1| 0.685714|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.857143|\n",
      "+----+---------+---------+\n",
      "|   4|        1|      0.9|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.714286|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.557143|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.285714|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 29 seconds.\n",
      "\n",
      "===== TRAINING 15-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00167376\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   4|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.871429|\n",
      "+----+---------+---------+\n",
      "|   6|        1|      0.9|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.628571|\n",
      "+----+---------+---------+\n",
      "|   8|        1| 0.485714|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 33 seconds.\n",
      "\n",
      "===== TRAINING 16-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.00118898\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.814286|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.571429|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.542857|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.585714|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.457143|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 36 seconds.\n",
      "\n",
      "===== TRAINING 17-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.000938527\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1|      0.8|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.728571|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.414286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 38 seconds.\n",
      "\n",
      "===== TRAINING 18-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.000636236\n",
      "Precalculation time: 1\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.885714|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.914286|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.542857|\n",
      "+----+---------+---------+\n",
      "|   6|        1|      0.7|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.428571|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 41 seconds.\n",
      "\n",
      "===== TRAINING 19-stage =====\n",
      "<BEGIN\n",
      "POS count : consumed   100 : 100\n",
      "NEG count : acceptanceRatio    70 : 0.000421598\n",
      "Precalculation time: 0\n",
      "+----+---------+---------+\n",
      "|  N |    HR   |    FA   |\n",
      "+----+---------+---------+\n",
      "|   1|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   2|        1|        1|\n",
      "+----+---------+---------+\n",
      "|   3|        1| 0.857143|\n",
      "+----+---------+---------+\n",
      "|   4|        1| 0.685714|\n",
      "+----+---------+---------+\n",
      "|   5|        1| 0.528571|\n",
      "+----+---------+---------+\n",
      "|   6|        1| 0.628571|\n",
      "+----+---------+---------+\n",
      "|   7|        1| 0.557143|\n",
      "+----+---------+---------+\n",
      "|   8|        1| 0.414286|\n",
      "+----+---------+---------+\n",
      "END>\n",
      "Training until now has taken 0 days 0 hours 0 minutes 45 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='opencv_traincascade -data params -vec positives.vec -bg no_faces.csv -numPos 100 -numNeg 70', returncode=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "#os.chdir(\"./dataset/\")\n",
    "\n",
    "# Definisci il comando da eseguire\n",
    "command = 'opencv_traincascade -data params -vec positives.vec -bg no_faces.csv -numPos 100 -numNeg 70'\n",
    "\n",
    "# Esegui il comando\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad773a27-4582-4053-832b-4a228d61ea5d",
   "metadata": {},
   "source": [
    "# 5. Utilizzo del Classificatore a cascata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace0531-74c1-4b93-bb2c-11d4253edb94",
   "metadata": {},
   "source": [
    "Dopo aver completato con successo l'addestramento del classificatore utilizzando **opencv_traincascade** e aver ottenuto il classificatore in un file XML, possiamo ora impiegare questo classificatore per identificare gli oggetti di interesse, come i volti, nelle immagini o nei video.\n",
    "\n",
    "Questo file XML contiene tutte le informazioni necessarie per il riconoscimento degli oggetti addestrati, permettendo al nostro software o script di OpenCV di analizzare nuove immagini o flussi video e di identificare i volti con precisione. L'utilizzo del classificatore addestrato per la rilevazione in scenari reali rappresenta l'ultima fase del processo di machine learning, consentendo l'applicazione pratica delle competenze acquisite e della tecnologia sviluppata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556acc72-8b91-41d8-b456-d88e08460a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Carica il classificatore addestrato da file\n",
    "cascade = cv2.CascadeClassifier('params/cascade.xml')\n",
    "\n",
    "# Carica l'immagine su cui effettuare il rilevamento\n",
    "image = cv2.imread('../dataset/faces/00000006.jpg')\n",
    "\n",
    "# Converti l'immagine in scala di grigi (necessario per il rilevamento Haar)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Rileva gli oggetti nell'immagine\n",
    "objects = cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Disegna rettangoli intorno agli oggetti rilevati\n",
    "for (x, y, w, h) in objects:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Mostra l'immagine con gli oggetti rilevati\n",
    "cv2.imshow('Objects detected', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79560fe7-178e-4de6-9f42-306523b92cb6",
   "metadata": {},
   "source": [
    "# 6. Implementazione di una Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a6bb0-c5a4-4029-9251-b51622208eac",
   "metadata": {},
   "source": [
    "Con tutti gli elementi a disposizione, procederemo a sviluppare una pipeline che, ricevendo in input un'immagine, sia capace di fornire in output una lista contenente le coordinate dei rettangoli che individuano i volti rilevati nell'immagine stessa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf90b0-9f1b-4eb0-8a06-2b6c9146a804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def detect_obj(image_path,classifier_path):\n",
    "\n",
    "    # Carica il classificatore addestrato da file\n",
    "    cascade = cv2.CascadeClassifier(classifier_path)\n",
    "\n",
    "    # Carica l'immagine su cui effettuare il rilevamento\n",
    "    image = cv2.imread('image_path)\n",
    "\n",
    "    # Converti l'immagine in scala di grigi (necessario per il rilevamento Haar)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Rileva gli oggetti nell'immagine\n",
    "    objects = cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    return objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
